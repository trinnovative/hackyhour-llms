{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:41.496919700Z",
     "start_time": "2023-11-02T09:39:41.464732800Z"
    }
   },
   "id": "af6a1b4b9056f760"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LangChain\n",
    "- Open-source Framework\n",
    "- Python, JS/TS\n",
    "- Kombination von LLMs mit externen Funktionalitäten und Daten"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "387bdd6d05b1275a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model I/O\n",
    "\n",
    "### Prompts\n",
    "Die Anweisung/Frage/Aufgabestellung die das Modell bearbeiten soll.\n",
    "\n",
    "### Language Models\n",
    "Interfaces und Integrationen von verschiedenen Modellen\n",
    "- LLMs: input text → output text (z.B. `text-davinci-003`)\n",
    "- Chat models: input Liste von Chatnachrichten (System, Human, AI) → output Chatnachricht (z.B. `gpt-3.5-turbo`)\n",
    "\n",
    "### Output Parsers\n",
    "Wandeln die Textausgabe der Modelle in strukturierte Daten um."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e82bd7bdd6e6b99"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant who generates comma separated lists. A user will pass in a category, and you should generate 5 objects in that category in a comma separated list. ONLY return a comma separated list, and nothing more.'), HumanMessage(content='programming languages')])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = (\"You are a helpful assistant who generates comma separated lists. \"\n",
    "                   \"A user will pass in a category, and you should generate 5 objects in that category in a comma separated list. \"\n",
    "                   \"ONLY return a comma separated list, and nothing more.\")\n",
    "human_template = \"{text}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "prompt_template.invoke({\"text\": \"programming languages\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:41.925117500Z",
     "start_time": "2023-11-02T09:39:41.472923400Z"
    }
   },
   "id": "476618f2b18ea11b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='Hello! How can I assist you today?')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# default: gpt-3.5-turbo\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "llm.invoke(\"hi!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:42.990002900Z",
     "start_time": "2023-11-02T09:39:41.922119700Z"
    }
   },
   "id": "a8f9650d71065b79"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['python', 'typescript']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "parser.invoke(\"python, typescript\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:43.023621600Z",
     "start_time": "2023-11-02T09:39:42.984988Z"
    }
   },
   "id": "6e83e45ece34069b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chains\n",
    "Chains erlauben es mehrere Modelle (LLM, Chat) und Komponenten (Prompt, Parser, Retriever) zu verknüpfen.\n",
    "Für das Erstellen von Chains wird vorrangig die [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/) verwendet.\n",
    "\n",
    "```python\n",
    "chain = prompt | model | parser\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e5c0d2fa441f23e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['Python', 'Java', 'C++', 'JavaScript', 'Ruby']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | llm | parser\n",
    "\n",
    "chain.invoke({\"text\": \"programming languages\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:44.196875800Z",
     "start_time": "2023-11-02T09:39:43.024623Z"
    }
   },
   "id": "5f727cd73d7a8e80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Memory\n",
    "- Informationen aus vorausgegangenen Konversationen speichern\n",
    "- Speichern und abrufen von Informationen (reading/writing)\n",
    "- Mit Tokenlimit umgehen"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e250ac5d8db585f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True    \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:44.736045Z",
     "start_time": "2023-11-02T09:39:44.194875600Z"
    }
   },
   "id": "411c67a682be4716"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: hi! My name is Dave\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'hi! My name is Dave',\n 'history': '',\n 'response': \"Hello Dave! It's nice to meet you. How can I assist you today?\"}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"hi! My name is Dave\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:46.171698600Z",
     "start_time": "2023-11-02T09:39:44.736045Z"
    }
   },
   "id": "991584c565d5f45b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: hi! My name is Dave\n",
      "AI: Hello Dave! It's nice to meet you. How can I assist you today?\n",
      "Human: What is my name?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'What is my name?',\n 'history': \"Human: hi! My name is Dave\\nAI: Hello Dave! It's nice to meet you. How can I assist you today?\",\n 'response': 'Your name is Dave.'}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"What is my name?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:46.836239800Z",
     "start_time": "2023-11-02T09:39:46.145652400Z"
    }
   },
   "id": "e53594d26eb47c07"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[HumanMessage(content='hi! My name is Dave'),\n AIMessage(content=\"Hello Dave! It's nice to meet you. How can I assist you today?\"),\n HumanMessage(content='What is my name?'),\n AIMessage(content='Your name is Dave.')]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.memory.chat_memory.messages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:46.837247400Z",
     "start_time": "2023-11-02T09:39:46.833613100Z"
    }
   },
   "id": "717ee77c618fd524"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieval\n",
    "- Einbindung von Daten, die nicht Teil des Trainingssets des Modells sind\n",
    "- Retrieval Augmented Generation (RAG) \n",
    "- Dokumente laden/transformieren, Embeddings, Vector Stores, Retrievers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5396deb3f3274e68"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:46.941938200Z",
     "start_time": "2023-11-02T09:39:46.838247Z"
    }
   },
   "id": "910c614705506fc7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts([\"Hacky Hour: Large Language Models for Developers \"\n",
    "                                \"anwenden, integrieren und erweitern, \"\n",
    "                                \"Degginger Regensburg, 14.11.2023, Einlass 18:00 Uhr, Start 18:30 Uhr\"], embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:47.615950200Z",
     "start_time": "2023-11-02T09:39:46.942937900Z"
    }
   },
   "id": "bb51de2626858328"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'Die Hacky Hour findet am 14.11.2023 in Degginger Regensburg statt.'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Wann und wo findet die Hacky Hour statt?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:49.135986600Z",
     "start_time": "2023-11-02T09:39:47.615950200Z"
    }
   },
   "id": "7f1f57bc55d4996c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'Die Hacky Hour startet um 18:30 Uhr.'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Um wie viel Uhr Startet die Hacky Hour?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:50.339830Z",
     "start_time": "2023-11-02T09:39:49.136999300Z"
    }
   },
   "id": "188c38a026e3aedf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agents\n",
    "- Agents erlauben LLMs mit ihrer Umgebung zu interagieren (Funktionen, APIs).\n",
    "- LLMs werden als Reasoning-Engine genutzt um zu entscheiden welche Aktionen ausgeführt werden sollen (Chains sind hardcoded)\n",
    "- AgentAction: Welche Aktion soll ausgeführt werden (tool, tool_input)\n",
    "- AgentFinish: Ist der Agent mit seiner Arbeit fertig und soll das Ergebnis zurückgeben\n",
    "- intermediate_steps: Welche Schritte wurden bereits ausgeführt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac938ff65cd88e25"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType, load_tools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:50.422505300Z",
     "start_time": "2023-11-02T09:39:50.336829300Z"
    }
   },
   "id": "f77b98fb97c36bcb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-0613\", temperature=0)\n",
    "\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=llm)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:39:50.526771400Z",
     "start_time": "2023-11-02T09:39:50.421511200Z"
    }
   },
   "id": "2e9b0da2a78d57a8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m```json\n",
      "{\n",
      "    \"action\": \"duckduckgo_search\",\n",
      "    \"action_input\": \"Leonardo DiCaprio current girlfriend\"\n",
      "}\n",
      "```\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mIn the pictures, obtained by the Daily Mail, DiCaprio and Ceretti can be seen chatting in an outdoor veranda. According to TMZ, the actor was first there alone to get some \"fresh air\" when his ... Me-ow. Leonardo DiCaprio's new girlfriend, Vittoria Ceretti, and his ex-fling Gigi Hadid had a fashion face-off on the catwalk on Friday, both taking turns strutting their stuff in the Versace ... By. Eileen Reslen. Published Sep. 22, 2023, 5:15 p.m. ET. Leonardo DiCaprio is officially dating Vittoria Ceretti, Page Six can confirm. Getty Images for Global Citizen. Leonardo DiCaprio has a ... Leonardo DiCaprio's new girlfriend, Vittoria Ceretti, is meeting the family. ... 48, was spotted in a black baseball cap while exiting the museum accompanied by his mother and his current flame. Things seem to be heating up between Leonardo DiCaprio and his new girlfriend Vittoria Ceretti!. The new couple was spotted hanging out together at a Halloween party in Los Angeles over the ...\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m```json\n",
      "{\n",
      "    \"action\": \"duckduckgo_search\",\n",
      "    \"action_input\": \"Vittoria Ceretti age\"\n",
      "}\n",
      "```\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mGetty Images Ceretti was discovered as a model at the age of 14 at the Elite Model Look Model contest in 2012, according to the agency. Ranked as one of the \"New Supers\" of this generation by... Daniele Venturelli/WireImage At age 14, Ceretti made her modeling debut at Elite Model Look, one of the most prestigious international modeling competitions in the world. She was chosen as a... Who is Vittoria Ceretti? Vittoria Ceretti's journey to international stardom began when she was discovered as a model at the age of 14 by an Elite Model contest in 2012.. The 5-foot-9's impressive ... Leonardo DiCaprio might be looking to retire his reputation for bouncing from model to model by getting serious with Vittoria Ceretti. The actor's romance with the 25-year-old model has been ... Born on June 7, 1998, Vittoria Ceretti is a native of Brescia, Italy. She currently resides in Long Island.. At the age of 14, Ceretti made it to the final round of Elite's Model Look contest.\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m```json\n",
      "{\n",
      "    \"action\": \"Calculator\",\n",
      "    \"action_input\": \"25 * 3\"\n",
      "}\n",
      "```\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 75\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Leonardo DiCaprio's current girlfriend is Vittoria Ceretti, who is 25 years old. When her age is multiplied by 3, the result is 75.\"\n",
      "}\n",
      "```\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Who is leonardo di caprios current girlfriend and what is here age multiplied by 3?',\n 'chat_history': [HumanMessage(content='Who is leonardo di caprios current girlfriend and what is here age multiplied by 3?'),\n  AIMessage(content=\"Leonardo DiCaprio's current girlfriend is Vittoria Ceretti, who is 25 years old. When her age is multiplied by 3, the result is 75.\")],\n 'output': \"Leonardo DiCaprio's current girlfriend is Vittoria Ceretti, who is 25 years old. When her age is multiplied by 3, the result is 75.\"}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"Who is leonardo di caprios current girlfriend and what is here age multiplied by 3?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:40:30.240038500Z",
     "start_time": "2023-11-02T09:39:50.526771400Z"
    }
   },
   "id": "b08a8f0b88e972f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OpenAI function with LangChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0746556627ee522"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:40:30.240038500Z",
     "start_time": "2023-11-02T09:40:30.238206Z"
    }
   },
   "id": "3b7fac4b8bd27193"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0)\n",
    "\n",
    "class TemperatureScale(str, Enum):\n",
    "    CELSIUS = \"celsius\"\n",
    "    FAHRENHEIT = \"fahrenheit\"\n",
    "\n",
    "class WeatherInput(BaseModel):\n",
    "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
    "    unit: TemperatureScale = Field(default=TemperatureScale.FAHRENHEIT)\n",
    "\n",
    "\n",
    "tools = [\n",
    "    StructuredTool(\n",
    "        name=\"get_current_weather\",\n",
    "        func=get_current_weather,\n",
    "        description=\"Get the current weather in a given location\",\n",
    "        args_schema=WeatherInput\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.OPENAI_FUNCTIONS, \n",
    "    verbose=True, \n",
    "    max_execution_time=30\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:40:30.262402Z",
     "start_time": "2023-11-02T09:40:30.242047300Z"
    }
   },
   "id": "123013e1d2313ce6"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `get_current_weather` with `{'location': 'Boston, MA'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{\"location\": \"Boston, MA\", \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}\u001B[0m\u001B[32;1m\u001B[1;3mThe current weather in Boston, MA is 72°F and it is sunny and windy.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': \"What's the weather like in Boston?\",\n 'output': 'The current weather in Boston, MA is 72°F and it is sunny and windy.'}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\"What's the weather like in Boston?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T09:40:32.364889100Z",
     "start_time": "2023-11-02T09:40:30.263401800Z"
    }
   },
   "id": "2d4ba39327567774"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
